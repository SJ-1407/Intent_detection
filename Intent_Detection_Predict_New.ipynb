{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Bw7ciTGKO3_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path_1 = \"SJ-14/Intent_Detection_Model\"\n",
        "model_1 = BertForSequenceClassification.from_pretrained(model_path_1,ignore_mismatched_sizes=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model_1.to(device)\n",
        "model_1.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9clplAlDKlHT",
        "outputId": "a28074f1-9c80-4ee0-dff2-435ae8048a97"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SJ-14/Intent_Detection_Model and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([21, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"What is the finance of this product?\"\n"
      ],
      "metadata": {
        "id": "1k4RWqc0KtUh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/sofmattress_train.csv')   #replace the file path with your file's path\n",
        "label_map = {label: idx for idx, label in enumerate(dataset['label'].unique())}"
      ],
      "metadata": {
        "id": "GuNXzclkLDOL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_label_map = {idx: label for label, idx in label_map.items()}\n",
        "\n"
      ],
      "metadata": {
        "id": "dCdNM3AoK4_x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(input_sentence):\n",
        "  encoding = tokenizer(\n",
        "    input_sentence,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\"\n",
        "  ).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model_1(\n",
        "        input_ids=encoding['input_ids'],\n",
        "        attention_mask=encoding['attention_mask']\n",
        "    )\n",
        "\n",
        "    logits = outputs.logits.to(device)\n",
        "\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "E19Dba4KLybi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class=predict_intent(input_sentence)"
      ],
      "metadata": {
        "id": "Owfiow5wMH9z"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_intent = reverse_label_map[predicted_class]\n",
        "\n",
        "print(f\"Input Sentence: {input_sentence}\")\n",
        "print(f\"Predicted Intent: {predicted_intent}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROMfx0jHMLMC",
        "outputId": "4810d729-c2ef-4019-c12a-338d10681e94"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: What is the finance of this product?\n",
            "Predicted Intent: COD\n"
          ]
        }
      ]
    }
  ]
}